{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Описание задачи\n",
    "\n",
    "Небольшой интернет-магазин попросил вас добавить ранжирование товаров в блок \"Смотрели ранее\" - в нем теперь надо показывать не последние просмотренные пользователем товары, а те товары из просмотренных, которые он наиболее вероятно купит. Качество вашего решения будет оцениваться по количеству покупок в сравнении с прошлым решением в ходе А/В теста, т.к. по доходу от продаж статзначимость будет достигаться дольше из-за разброса цен. Таким образом, ничего заранее не зная про корреляцию оффлайновых и онлайновых метрик качества, в начале проекта вы можете лишь постараться оптимизировать recall@k и precision@k.\n",
    "\n",
    "Это задание посвящено построению простых бейзлайнов для этой задачи: ранжирование просмотренных товаров по частоте просмотров и по частоте покупок. Эти бейзлайны, с одной стороны, могут помочь вам грубо оценить возможный эффект от ранжирования товаров в блоке - например, чтобы вписать какие-то числа в коммерческое предложение заказчику, а с другой стороны, могут оказаться самым хорошим вариантом, если данных очень мало (недостаточно для обучения даже простых моделей).\n",
    "\n",
    "#### Входные данные\n",
    "\n",
    "Вам дается две выборки с пользовательскими сессиями - id-шниками просмотренных и id-шниками купленных товаров. Одна выборка будет использоваться для обучения (оценки популярностей товаров), а другая - для теста.\n",
    "\n",
    "В файлах записаны сессии по одной в каждой строке. Формат сессии: id просмотренных товаров через , затем идёт ; после чего следуют id купленных товаров (если такие имеются), разделённые запятой. Например, 1,2,3,4; или 1,2,3,4;5,6.\n",
    "\n",
    "Гарантируется, что среди id купленных товаров все различные.\n",
    "\n",
    "#### Важно:\n",
    "\n",
    "* Сессии, в которых пользователь ничего не купил, исключаем из оценки качества.\n",
    "* Если товар не встречался в обучающей выборке, его популярность равна 0.\n",
    "* Рекомендуем разные товары. И их число должно быть не больше, чем количество различных просмотренных пользователем товаров.\n",
    "* Рекомендаций всегда не больше, чем минимум из двух чисел: количество просмотренных пользователем товаров и k в recall@k / precision@k.\n",
    "\n",
    "#### Задание\n",
    "\n",
    "1. На обучении постройте частоты появления id в просмотренных и в купленных (id может несколько раз появляться в просмотренных, все появления надо учитывать)\n",
    "2. Реализуйте два алгоритма рекомендаций:\n",
    "* сортировка просмотренных id по популярности (частота появления в просмотренных),\n",
    "* сортировка просмотренных id по покупаемости (частота появления в покупках).\n",
    "3. Для данных алгоритмов выпишите через пробел AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5 на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие? Обратите внимание на различие качества на обучающей и тестовой выборке в случае рекомендаций по частотам покупки.\n",
    "\n",
    "Если частота одинаковая, то сортировать нужно по возрастанию момента просмотра (чем раньше появился в просмотренных, тем больше приоритет)\n",
    "\n",
    "#### Дополнительные вопросы\n",
    "\n",
    "Обратите внимание, что при сортировке по покупаемости возникает много товаров с одинаковым рангом - это означает, что значение метрик будет зависеть от того, как мы будем сортировать товары с одинаковым рангом. Попробуйте убедиться, что при изменении сортировки таких товаров recall@k меняется. Подумайте, как оценить минимальное и максимальное значение recall@k в зависимости от правила сортировки.\n",
    "Мы обучаемся и тестируемся на полных сессиях (в которых есть все просмотренные за сессию товары). Подумайте, почему полученная нами оценка качества рекомендаций в этом случае несколько завышена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"coursera_sessions_train.txt\", \";\", header = 0, names = [\"viewed\", \"bought\"])\n",
    "data_test = pd.read_csv(\"coursera_sessions_test.txt\", \";\", header = 0, names = [\"viewed\", \"bought\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewed</th>\n",
       "      <th>bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9,10,11,9,11,12,9,11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16,17,18,19,20,21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24,25,26,27,24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34,35,36,34,37,35,36,37,38,39,38,39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                viewed bought\n",
       "0                 9,10,11,9,11,12,9,11    NaN\n",
       "1                    16,17,18,19,20,21    NaN\n",
       "2                       24,25,26,27,24    NaN\n",
       "3  34,35,36,34,37,35,36,37,38,39,38,39    NaN\n",
       "4                                   42    NaN"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_session_string(string):\n",
    "    return [int(val) for val in string.split(\",\")]\n",
    "\n",
    "def parse_session(views_string, buys_string):\n",
    "    return (parse_session_string(views_string), parse_session_string(buys_string) if isinstance(buys_string, str) else [])\n",
    "\n",
    "def update_frequencies(items, frequencies):\n",
    "    for item in items:\n",
    "        frequencies[item] = frequencies[item] + 1 if item in frequencies else 1\n",
    "\n",
    "def build_data_frequencies(data):\n",
    "    views_freq = {}\n",
    "    buys_freq = {}\n",
    "    for views_string, buys_string in data.values:\n",
    "        views, buys = parse_session(views_string, buys_string)\n",
    "        update_frequencies(views, views_freq)\n",
    "        update_frequencies(buys, buys_freq)\n",
    "    return (views_freq, buys_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Merge sort module \"\"\"\n",
    "\n",
    "def merge(left_list, left_length, right_list, right_length, key, descending):\n",
    "    \"\"\" applies ordered merging of two lists based on key \"\"\"\n",
    "    left_index = 0\n",
    "    right_index = 0\n",
    "    result = []\n",
    "    if descending:\n",
    "        less_than = (lambda right, left: right > left)\n",
    "    else:\n",
    "        less_than = (lambda right, left: right < left)\n",
    "    while left_index < left_length and right_index < right_length:\n",
    "        left = left_list[left_index]\n",
    "        right = right_list[right_index]\n",
    "        if less_than(key(right), key(left)):\n",
    "            result.append(right)\n",
    "            right_index += 1\n",
    "        else:\n",
    "            result.append(left)\n",
    "            left_index += 1\n",
    "    if left_index == left_length:\n",
    "        return result + right_list[right_index:right_length]\n",
    "    else:\n",
    "        return result + left_list[left_index:left_length]\n",
    "\n",
    "def merge_sort(data, key, descending=False):\n",
    "    \"\"\" Applies merge sort in data based on key \"\"\"\n",
    "    list_length = len(data)\n",
    "    if list_length > 1:\n",
    "        left_length = int(list_length/2)\n",
    "        right_length = list_length-left_length\n",
    "        left_list = merge_sort(data[0:left_length], key, descending)\n",
    "        right_list = merge_sort(data[left_length:list_length], key, descending)\n",
    "\n",
    "        return merge(left_list, left_length, right_list, right_length, key, descending)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_frequencies, buys_frequencies =  build_data_frequencies(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity(view, frequencies):\n",
    "    return float(frequencies[view] if view in frequencies else 0)\n",
    "\n",
    "def unique_values(data, key):\n",
    "    values = {}\n",
    "    result = []\n",
    "    for value in data:\n",
    "        k = key(value)\n",
    "        if k not in values:\n",
    "            result.append(value)\n",
    "            values[k] = True\n",
    "    return result\n",
    "\n",
    "def build_recommendations(views, frequencies, k):\n",
    "    views_popularity = [(view, popularity(view, frequencies)) for view in views]\n",
    "    sorted_views = merge_sort(views_popularity, lambda v: v[1], descending = True)\n",
    "    recommendations_len = min(k, len(set(views)))\n",
    "    return [view for (view, pop) in unique_values(sorted_views, lambda v: v[0])][:recommendations_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(buys, recommendations, k):\n",
    "    recommendations_in_buys = [1 if recommendation in buys else 0 for recommendation in recommendations]\n",
    "    return float(sum(recommendations_in_buys))/float(k)\n",
    "\n",
    "def recall(buys, recommendations):\n",
    "    recommendations_in_buys = [1 if recommendation in buys else 0 for recommendation in recommendations]\n",
    "    return float(sum(recommendations_in_buys))/float(len(buys)) if len(recommendations_in_buys) > 0 else 0.\n",
    "\n",
    "def estimate_model(data, model, k):\n",
    "    precision_sum = 0.\n",
    "    recall_sum = 0.\n",
    "    for views_string, buys_string in data.values:\n",
    "        views, buys = parse_session(views_string, buys_string)\n",
    "        recommendations = model(views, k)\n",
    "        precision_sum += precision(buys, recommendations, k)\n",
    "        recall_sum += recall(buys, recommendations)\n",
    "    data_length = float(len(data))\n",
    "    return (recall_sum/data_length, precision_sum/data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View frequency model\n",
      "Train\n",
      "1 :\n",
      "0.44 0.51\n",
      "5 :\n",
      "0.82 0.21\n",
      "Test\n",
      "1 :\n",
      "0.42 0.48\n",
      "5 :\n",
      "0.8 0.2\n",
      "Purchase frequency model\n",
      "Train\n",
      "1 :\n",
      "0.69 0.8\n",
      "5 :\n",
      "0.93 0.25\n",
      "Test\n",
      "1 :\n",
      "0.46 0.53\n",
      "5 :\n",
      "0.82 0.21\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    (\"View frequency model\", lambda views, k: build_recommendations(views, views_frequencies, k)),\n",
    "    (\"Purchase frequency model\", lambda views, k: build_recommendations(views, buys_frequencies, k))\n",
    "]\n",
    "\n",
    "datas = [\n",
    "    (\"Train\", data_train),\n",
    "    (\"Test\", data_test)\n",
    "]\n",
    "\n",
    "ks = [1, 5]\n",
    "\n",
    "data_train = data_train.dropna()\n",
    "data_test = data_test.dropna()\n",
    "\n",
    "for model_name, model in models:\n",
    "    print(model_name)\n",
    "    for data_name, data in datas:\n",
    "        print(data_name)\n",
    "        for k in ks:\n",
    "            print(k, \":\")\n",
    "            average_recall, average_precision = estimate_model(data, model, k)\n",
    "            print(np.round(average_recall, 2), np.round(average_precision, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
